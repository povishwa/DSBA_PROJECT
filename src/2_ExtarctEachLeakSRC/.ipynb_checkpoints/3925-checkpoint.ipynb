{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d141652",
   "metadata": {},
   "source": [
    "NAME : VISHWAKARMA POOJA RAMASHANKAR \n",
    "SR.NO : 00-0-0-40-52-22-1-21633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ccb4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c48b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766215b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"../data/RawLeakData/3925.csv\")\n",
    "print(data_df.shape)\n",
    "print(data_df[\"Meter ID\"].unique())\n",
    "data_df[\"Date\"] = pd.to_datetime(data_df[\"Date\"], errors='coerce')\n",
    "data_df[\"Time\"] = pd.to_datetime(data_df[\"Time\"], errors='coerce')\n",
    "data_df['Date'] = data_df['Date'] +  pd.to_timedelta(data_df['Time'].dt.hour, unit='h')\n",
    "data_df['Date'] = data_df['Date'] +  pd.to_timedelta(data_df['Time'].dt.minute, unit='m')\n",
    "data_df = data_df.drop(['Time'],axis=1)\n",
    "data_df = data_df.set_axis(['Leak', 'Date', 'Flowrate', 'Netflow', 'Pressure', 'ID'], axis=1)\n",
    "data_df.loc[(data_df[\"ID\"] == 'SE3DM0202'), \"ID\"] = 1\n",
    "data_df.loc[(data_df[\"ID\"] == 'S3DM0805'), \"ID\"] = 2\n",
    "data_df.loc[(data_df[\"ID\"] == 'SE3DM0101'), \"ID\"] = 3\n",
    "data_df.loc[(data_df[\"ID\"] == 'SW4SM0701'), \"ID\"] = 4\n",
    "data_df.loc[(data_df[\"ID\"] == 'SW4SM0702'), \"ID\"] = 5\n",
    "data_df.loc[(data_df[\"ID\"] == 'S3DM0804'), \"ID\"] = 6\n",
    "\n",
    "filtered_df1 = data_df.loc[(data_df['ID'] == 1)]\n",
    "filtered_df2 = data_df.loc[(data_df['ID'] == 2)]\n",
    "filtered_df3 = data_df.loc[(data_df['ID'] == 3)]\n",
    "filtered_df4 = data_df.loc[(data_df['ID'] == 4)]\n",
    "filtered_df5 = data_df.loc[(data_df['ID'] == 5)]\n",
    "filtered_df6 = data_df.loc[(data_df['ID'] == 6)]\n",
    "\n",
    "dta = pd.merge(\n",
    "    pd.merge(\n",
    "        pd.merge(\n",
    "            pd.merge(\n",
    "                pd.merge(filtered_df1, filtered_df2, on='Date', suffixes=(\"_1\", \"_2\")),\n",
    "                filtered_df3, on='Date', suffixes=(\"_3\", \"_4\")\n",
    "            ),\n",
    "            filtered_df4, on=\"Date\", suffixes=(\"_5\", \"_6\")\n",
    "        ),\n",
    "        filtered_df5, on=\"Date\", suffixes=(\"_7\", \"_8\")\n",
    "    ),\n",
    "    filtered_df6, on=\"Date\", suffixes=(\"_9\", \"_10\")\n",
    ")\n",
    "# Apply z-score normalization and filtering for Flowrate columns\n",
    "for i in range(1, 7):\n",
    "    flowrate_column = f\"Flowrate_{i}\"\n",
    "    if flowrate_column in dta.columns:\n",
    "        # Convert the column to numeric type to exclude non-numeric values\n",
    "        dta[flowrate_column] = pd.to_numeric(dta[flowrate_column], errors='coerce')\n",
    "        dta = dta[(np.abs(stats.zscore(dta[[flowrate_column]], nan_policy='omit')) < 2).all(axis=1)]\n",
    "\n",
    "# Apply z-score normalization and filtering for Pressure columns\n",
    "for i in range(1, 7):\n",
    "    pressure_column = f\"Pressure_{i}\"\n",
    "    if pressure_column in dta.columns:\n",
    "        # Convert the column to numeric type to exclude non-numeric values\n",
    "        dta[pressure_column] = pd.to_numeric(dta[pressure_column], errors='coerce')\n",
    "        dta = dta[(np.abs(stats.zscore(dta[[pressure_column]], nan_policy='omit')) < 2).all(axis=1)]\n",
    "dta.loc[:,\"LeakStatus\"] = 0\n",
    "dta.loc[(dta['Date'] >= '2017-11-01') & (dta['Date'] <= '2018-01-06'), \"LeakStatus\"] = 1\n",
    "# TODO: To check with Sir\n",
    "# fig, axs = plt.subplots(1, 1)\n",
    "# #plt.ylim((0,20))\n",
    "# plt.xticks(rotation=90)\n",
    "# axs.scatter(dta[\"Date\"],dta[\"Pressure_2\"], marker='*', s=1)\n",
    "# #axs.scatter(filtered_pdf2[\"Date\"],filtered_pdf2[\"Pressure\"], c='g', marker='.', s=1)\n",
    "# #axs.scatter(filtered_pdf3[\"Date\"],filtered_pdf3[\"Pressure\"], c='r', marker='.', s=1)\n",
    "# #axs.scatter(filtered_pdf4[\"Date\"],filtered_pdf4[\"Pressure\"], c='y', marker='.', s=1)\n",
    "# axs.axvline(x = pd.Timestamp('2017-12-09'), color = 'r')\n",
    "# Creating the directory if it doesn't exist\n",
    "output_directory = \"../data/EachLeakData\"\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "dta.to_csv(\"../data/EachLeakData/3925.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f691df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dta.shape)\n",
    "print(dta.isna().sum())\n",
    "print(dta.columns)\n",
    "dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302db44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the features and target\n",
    "X = dta[['Leak_1', 'Flowrate_1', 'Pressure_1', 'Flowrate_2', 'Pressure_2',\n",
    "         'Flowrate_5', 'Pressure_5', 'Flowrate_6', 'Pressure_6',  \n",
    "         'Flowrate_9','Pressure_9','Flowrate_10', 'Pressure_10']]\n",
    "y = dta['LeakStatus']\n",
    "print(X)\n",
    "print(y)\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the models to evaluate\n",
    "models = [\n",
    "    ('SVM', SVC(C=3000000.0, kernel='rbf', class_weight='balanced')),\n",
    "    ('MLP', MLPClassifier(hidden_layer_sizes=(1000, 100, 10), activation='relu', max_iter=3000000000))\n",
    "]\n",
    "\n",
    "# Loop through each model and evaluate\n",
    "for name, model in models:\n",
    "    # Training the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    # Making predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "    print(f'Train Accuracy: {model.score(X_train, y_train)}')\n",
    "    print(f'Test Accuracy: {model.score(X_test, y_test)}')\n",
    "    print(f\"{name} Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "    # Printing the first 25 rows of predictions and actual values\n",
    "    print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.values.reshape(len(y_test), 1)), axis=1)[:25])\n",
    "\n",
    "    # Plotting confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f6c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5e04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db575d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
